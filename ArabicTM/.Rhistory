library(devtools)
install_github('rCharts', 'ramnathv')
install.packages("devtools")
library(devtools)
install_github('rCharts', 'ramnathv')
require(XML)
require(rCharts)
# URL of the task view (thanks Roger Bivand)
url<-"http://cran.r-project.org/web/views/Spatial.html"
# grab list of packages
spat<-readHTMLList(url, stringsAsFactors = F)[[2]]
# For cleanliness drop the word '(core)' from the package name
spat<-gsub(" \\(core\\)", "", spat)
getPkgInfo<-function(pkg){
url = paste("http://cran.r-project.org/web/packages/", pkg, "/index.html", sep="")
# get table of details and extract most current date
dtl<-readHTMLTable(url, stringsAsFactors = F)[[1]]
curdate<-dtl[which(dtl[,1]=="Published:"),2]
# get first archive date
url = paste('http://cran.r-project.org/src/contrib/Archive/', pkg, '/', sep="")
packages = try(readHTMLTable(url, stringsAsFactors = F)[[1]][-1,])
# if there is no archive first date is current date
if(class(packages)=='try-error'){
print("in error")
firstdate<-as.Date(curdate)
#otherwise get first archive date
}else{
packages<-packages[-1,]
firstdate<-as.Date(packages[1,"Last modified"],"%d-%b-%Y %H:%M")
}
return(data.frame(pkg=pkg, firstdate=firstdate, curdate=curdate))
}
pkgdates<-do.call("rbind", lapply(spat, getPkgInfo))
install.packages("shiny")
library(shiny)
runExample("01_hello")
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runGitHub("LDAvis", "cpsievert", subdir = "inst/examples/shiny")
devtools::install_github("cpsievert/LDAvis@shiny")
rmarkdown::run(system.file("examples/rmarkdown.Rmd", package = "LDAvis"))
shiny::runApp('OneDrive/shiny/App-1')
devtools::install_github("cpsievert/LDAvis")
library(LDAvis)
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
add_stopwords <- c("asdfnods f;safnkladsfn AFm;dfn; ansd;lfn;f")
user_stopwords <- strsplit(add_stopwords, " ")
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
captureOutput()
capture.output()
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
shiny::runApp('OneDrive/shiny/App-1')
URL <- https://raw.githubusercontent.com/OpenGreekAndLatin/csel-dev/master/CSEL01.xml
URL <- "https://raw.githubusercontent.com/OpenGreekAndLatin/csel-dev/master/CSEL01.xml"
URLcontent <- getURLContent(URL)
library(tm)
library(XML)
library(RCurl)
library(plyr)
library(lda)
library(LDAvis)
URLcontent <- getURLContent(URL)
doc <- xmlTreeParse(URLcontent, getDTD = F)
rootnode <- xmlRoot(doc)
results <- xmlChildren(rootnode)[2][[1]]
results
head(results)
doc
rootnode
catalogue_temp <- xmlSApply(results, function(x) xmlSApply(x, xmlValue))
catalogue_temp.df <- t(data.frame(catalogue_temp))
catalogue_temp.df <- t(data.frame(catalogue_temp))
View(catalogue_temp.df)
results <- xmlChildren(rootnode)[2][[1]][[[1]]]
xmlSize(results)
xmlSize(doc)
node[1:3]
xmlValue(results)
what <- xmlValue(results)
what <- as.data.frame(what)
View(what)
what <- xmlValue(rootnode)
what
xmlAttrs(results)
xmlAttrs(doc)
xmlAttrs(rootnode)
xmlName(results)
xmlName(rootnode)
xmlNames(rootnode)
xmlName(rootnode)
what <- xmlChildren(results)[1]
xmlName(what)
what
what2 <- as.data.frame(what)
what
xmlElementSummary(results)
xmlElementSummary(results)
library(xml)
library(XML)
xmlElementSummary(results)
xmlElementsByTagName(el, name, recursive = FALSE)
xmlElementsByTagName(results, "name", recursive = FALSE)
xmlElementsByTagName(results, "div", recursive = FALSE)
xmlElementsByTagName(doc, "div", recursive = FALSE)
xmlElementsByTagName(rootnode, "div", recursive = FALSE)
xmlElementsByTagName(rootnode, "body", recursive = FALSE)
xmlElementsByTagName(rootnode, "p", recursive = FALSE)
xmlEventParse(system.file(doc, package="XML"),              handlers=xmlEventHandler())
what <- xmlTolist(doc)
what <- xmlToList(doc)
what <- xmlToList(rootnode)
what2 <- xmlToList(results)
View(what2)
what2
what2[1,]
what <- what2[1,]
what <- as.data.frame(what)
what <- what2[1,]
what <- unlist(what)
what
head(what)
what[1:3]
what <- what2[1,]
what[1:3]
what$body$p$text
what <- what2[1,]
what <- as.vectort(what2[1,])
what <- as.vector(what2[1,])
what
what$body$p
what$body
what$body$p
shiny::runApp('OneDrive/shiny/tmApp')
latin_endings <- c("a", "am", "am", "am", "am", "am", "amini", "amini", "amini", "amur", "amur", "amur", "amus", "amus", "amus", "ant", "ant", "ant", "antur", "antur", "antur", "ar", "ar", "ar", "ar", "ar", "aris", "aris", "aris", "as", "as", "as", "at", "at", "at", "ate", "atis", "atis", "atis", "atur", "atur", "atur", "bam", "bam", "bamini", "bamini", "bamur", "bamur", "bamus", "bamus", "bant", "bant", "bantur", "bantur", "bar", "bar", "baris", "baris", "bas", "bas", "bat", "bat", "batis", "batis", "batur", "batur", "beris", "beris", "bimini", "bimini", "bimur", "bimur", "bimus", "bimus", "bis", "bis", "bit", "bit", "bitis", "bitis", "bitur", "bitur", "bo", "bo", "bor", "bor", "bunt", "bunt", "buntur", "buntur", "e", "e", "e", "ebam", "ebam", "ebamini", "ebamini", "ebamur", "ebamur", "ebamus", "ebamus", "ebant", "ebant", "ebantur", "ebantur", "ebar", "ebar", "ebaris", "ebaris", "ebas", "ebas", "ebat", "ebat", "ebatis", "ebatis", "ebatur", "ebatur", "em", "emini", "emini", "emini", "emur", "emur", "emur", "emus", "emus", "emus", "ent", "ent", "ent", "entur", "entur", "entur", "er", "erim", "erim", "erim", "erim", "erim", "erimus", "erimus", "erimus", "erimus", "erimus", "erimus", "erimus", "erimus", "erimus", "erimus", "erint", "erint", "erint", "erint", "erint", "erint", "erint", "erint", "erint", "erint", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "erit", "erit", "erit", "erit", "erit", "erit", "erit", "erit", "erit", "erit", "eritis", "eritis", "eritis", "eritis", "eritis", "eritis", "eritis", "eritis", "eritis", "eritis", "ero", "ero", "ero", "ero", "ero", "erunt", "erunt", "erunt", "erunt", "erunt", "es", "es", "es", "et", "et", "et", "ete", "etis", "etis", "etis", "etur", "etur", "etur", "i", "i", "i", "i", "i", "i", "iam", "iam", "iamini", "iamur", "iamus", "iant", "iantur", "iar", "iar", "iaris", "ias", "iat", "iatis", "iatur", "iebam", "iebamini", "iebamur", "iebamus", "iebant", "iebantur", "iebar", "iebaris", "iebas", "iebat", "iebatis", "iebatur", "iemini", "iemur", "iemus", "ient", "ientur", "ieris", "ies", "iet", "ietis", "ietur", "imini", "imini", "imur", "imur", "imus", "imus", "imus", "imus", "imus", "imus", "imus", "io", "ior", "is", "is", "isti", "isti", "isti", "isti", "isti", "istis", "istis", "istis", "istis", "istis", "it", "it", "it", "it", "it", "it", "it", "ite", "ite", "ite", "itis", "itis", "itur", "itur", "iunt", "iuntur", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "mini", "mini", "mini", "mini", "mini", "mini", "mini", "mini", "mur", "mur", "mur", "mur", "mur", "mur", "mur", "mur", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "ntur", "ntur", "ntur", "ntur", "ntur", "ntur", "ntur", "ntur", "o", "o", "o", "o", "or", "or", "or", "or", "r", "r", "r", "r", "r", "ris", "ris", "ris", "ris", "ris", "ris", "ris", "ris", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tur", "tur", "tur", "tur", "tur", "tur", "tur", "tur", "unt", "unt", "untur", "a", "ae", "ae", "am", "a", "ae", "arum", "is", "as", "is", "us", "i", "o", "um", "o", "i", "orum", "is", "os", "is", "is", "i", "em", "e", "ei", "es", "ium", "um", "ebus", "ibus")
latin_endings <- unique(latin_endings)
latin_endings <- latin_endings[order(nchar(latin_endings), latin_endings)]
latin_endings <- c("a", "am", "am", "am", "am", "am", "amini", "amini", "amini", "amur", "amur", "amur", "amus", "amus", "amus", "ant", "ant", "ant", "antur", "antur", "antur", "ar", "ar", "ar", "ar", "ar", "aris", "aris", "aris", "as", "as", "as", "at", "at", "at", "ate", "atis", "atis", "atis", "atur", "atur", "atur", "bam", "bam", "bamini", "bamini", "bamur", "bamur", "bamus", "bamus", "bant", "bant", "bantur", "bantur", "bar", "bar", "baris", "baris", "bas", "bas", "bat", "bat", "batis", "batis", "batur", "batur", "beris", "beris", "bimini", "bimini", "bimur", "bimur", "bimus", "bimus", "bis", "bis", "bit", "bit", "bitis", "bitis", "bitur", "bitur", "bo", "bo", "bor", "bor", "bunt", "bunt", "buntur", "buntur", "e", "e", "e", "ebam", "ebam", "ebamini", "ebamini", "ebamur", "ebamur", "ebamus", "ebamus", "ebant", "ebant", "ebantur", "ebantur", "ebar", "ebar", "ebaris", "ebaris", "ebas", "ebas", "ebat", "ebat", "ebatis", "ebatis", "ebatur", "ebatur", "em", "emini", "emini", "emini", "emur", "emur", "emur", "emus", "emus", "emus", "ent", "ent", "ent", "entur", "entur", "entur", "er", "erim", "erim", "erim", "erim", "erim", "erimus", "erimus", "erimus", "erimus", "erimus", "erimus", "erimus", "erimus", "erimus", "erimus", "erint", "erint", "erint", "erint", "erint", "erint", "erint", "erint", "erint", "erint", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "erit", "erit", "erit", "erit", "erit", "erit", "erit", "erit", "erit", "erit", "eritis", "eritis", "eritis", "eritis", "eritis", "eritis", "eritis", "eritis", "eritis", "eritis", "ero", "ero", "ero", "ero", "ero", "erunt", "erunt", "erunt", "erunt", "erunt", "es", "es", "es", "et", "et", "et", "ete", "etis", "etis", "etis", "etur", "etur", "etur", "i", "i", "i", "i", "i", "i", "iam", "iam", "iamini", "iamur", "iamus", "iant", "iantur", "iar", "iar", "iaris", "ias", "iat", "iatis", "iatur", "iebam", "iebamini", "iebamur", "iebamus", "iebant", "iebantur", "iebar", "iebaris", "iebas", "iebat", "iebatis", "iebatur", "iemini", "iemur", "iemus", "ient", "ientur", "ieris", "ies", "iet", "ietis", "ietur", "imini", "imini", "imur", "imur", "imus", "imus", "imus", "imus", "imus", "imus", "imus", "io", "ior", "is", "is", "isti", "isti", "isti", "isti", "isti", "istis", "istis", "istis", "istis", "istis", "it", "it", "it", "it", "it", "it", "it", "ite", "ite", "ite", "itis", "itis", "itur", "itur", "iunt", "iuntur", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "mini", "mini", "mini", "mini", "mini", "mini", "mini", "mini", "mur", "mur", "mur", "mur", "mur", "mur", "mur", "mur", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "ntur", "ntur", "ntur", "ntur", "ntur", "ntur", "ntur", "ntur", "o", "o", "o", "o", "or", "or", "or", "or", "r", "r", "r", "r", "r", "ris", "ris", "ris", "ris", "ris", "ris", "ris", "ris", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tur", "tur", "tur", "tur", "tur", "tur", "tur", "tur", "unt", "unt", "untur", "a", "ae", "ae", "am", "a", "ae", "arum", "is", "as", "is", "us", "i", "o", "um", "o", "i", "orum", "is", "os", "is", "is", "i", "em", "e", "ei", "es", "ium", "um", "ebus", "ibus")
latin_endings <- latin_endings[order(nchar(latin_endings)]
latin_endings <- order(nchar(latin_endings), latin_endings)
latin_endings
latin_endings <- c("a", "am", "am", "am", "am", "am", "amini", "amini", "amini", "amur", "amur", "amur", "amus", "amus", "amus", "ant", "ant", "ant", "antur", "antur", "antur", "ar", "ar", "ar", "ar", "ar", "aris", "aris", "aris", "as", "as", "as", "at", "at", "at", "ate", "atis", "atis", "atis", "atur", "atur", "atur", "bam", "bam", "bamini", "bamini", "bamur", "bamur", "bamus", "bamus", "bant", "bant", "bantur", "bantur", "bar", "bar", "baris", "baris", "bas", "bas", "bat", "bat", "batis", "batis", "batur", "batur", "beris", "beris", "bimini", "bimini", "bimur", "bimur", "bimus", "bimus", "bis", "bis", "bit", "bit", "bitis", "bitis", "bitur", "bitur", "bo", "bo", "bor", "bor", "bunt", "bunt", "buntur", "buntur", "e", "e", "e", "ebam", "ebam", "ebamini", "ebamini", "ebamur", "ebamur", "ebamus", "ebamus", "ebant", "ebant", "ebantur", "ebantur", "ebar", "ebar", "ebaris", "ebaris", "ebas", "ebas", "ebat", "ebat", "ebatis", "ebatis", "ebatur", "ebatur", "em", "emini", "emini", "emini", "emur", "emur", "emur", "emus", "emus", "emus", "ent", "ent", "ent", "entur", "entur", "entur", "er", "erim", "erim", "erim", "erim", "erim", "erimus", "erimus", "erimus", "erimus", "erimus", "erimus", "erimus", "erimus", "erimus", "erimus", "erint", "erint", "erint", "erint", "erint", "erint", "erint", "erint", "erint", "erint", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "eris", "erit", "erit", "erit", "erit", "erit", "erit", "erit", "erit", "erit", "erit", "eritis", "eritis", "eritis", "eritis", "eritis", "eritis", "eritis", "eritis", "eritis", "eritis", "ero", "ero", "ero", "ero", "ero", "erunt", "erunt", "erunt", "erunt", "erunt", "es", "es", "es", "et", "et", "et", "ete", "etis", "etis", "etis", "etur", "etur", "etur", "i", "i", "i", "i", "i", "i", "iam", "iam", "iamini", "iamur", "iamus", "iant", "iantur", "iar", "iar", "iaris", "ias", "iat", "iatis", "iatur", "iebam", "iebamini", "iebamur", "iebamus", "iebant", "iebantur", "iebar", "iebaris", "iebas", "iebat", "iebatis", "iebatur", "iemini", "iemur", "iemus", "ient", "ientur", "ieris", "ies", "iet", "ietis", "ietur", "imini", "imini", "imur", "imur", "imus", "imus", "imus", "imus", "imus", "imus", "imus", "io", "ior", "is", "is", "isti", "isti", "isti", "isti", "isti", "istis", "istis", "istis", "istis", "istis", "it", "it", "it", "it", "it", "it", "it", "ite", "ite", "ite", "itis", "itis", "itur", "itur", "iunt", "iuntur", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "m", "mini", "mini", "mini", "mini", "mini", "mini", "mini", "mini", "mur", "mur", "mur", "mur", "mur", "mur", "mur", "mur", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "mus", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "nt", "ntur", "ntur", "ntur", "ntur", "ntur", "ntur", "ntur", "ntur", "o", "o", "o", "o", "or", "or", "or", "or", "r", "r", "r", "r", "r", "ris", "ris", "ris", "ris", "ris", "ris", "ris", "ris", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "s", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "t", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tis", "tur", "tur", "tur", "tur", "tur", "tur", "tur", "tur", "unt", "unt", "untur", "a", "ae", "ae", "am", "a", "ae", "arum", "is", "as", "is", "us", "i", "o", "um", "o", "i", "orum", "is", "os", "is", "is", "i", "em", "e", "ei", "es", "ium", "um", "ebus", "ibus")
latin_endings <- unique(latin_endings)
latin_endings <- latin_endings[order(nchar(latin_endings), latin_endings)]
latin_endings <- rev(latin_endings)
savehistory("~/Desktop/test.Rhistory")
> string_name = c("aaaaa", "bbbbb", "ccccc", "dddd*", "eee*eee")
> substring(string_name, nchar(string_name)) == "*"
string_name = c("aaaaa", "bbbbb", "ccccc", "dddd*", "eee*eee")
substring(string_name, nchar(string_name)) == "*"
string_name = c("aaaaa", "bbbbb", "ccccc", "dddd*", "eee*eee")
substring(string_name, nchar(string_name)) == "aa"
string_name = c("aaaaa", "bbbbb", "ccccc", "dddd*", "eee*eee")
substring(string_name, nchar(string_name)) == "aa"
string_name = c("aaaaa", "bbbbb", "ccccc", "dddd*", "eee*eee")
substring(string_name, nchar(string_name)) == "a"
string_name = c("aaaaa", "bbbbb", "ccccc", "dddd*", "eee*eee")
substring(string_name, nchar(string_name)) == "*"
x <- c('aaaaa', 'bbbbb', 'ccccc', 'dddd*', 'eee*eee')
substr(x, nchar(x)-1+1, nchar(x)) == '*'
x <- c('aaaaa', 'bbbbb', 'ccccc', 'dddd*', 'eee*eee')
substr(x, nchar(x)-1+1, nchar(x)) == 'a'
x <- c('aaaaa', 'bbbbb', 'ccccc', 'dddd*', 'eee*eee')
substr(x, nchar(x)-1+1, nchar(x)) == 'b'
what <- c("this", "is", "a", "text")
what2 <- c("his", "is", "an")
diff(what, what2)
grepl(what, what2)
what2 <- c("his", "is", "an", "what")
grepl(what, what2)
what2 <- c("his", "is", "an", "text")
grepl(what, what2)
grepl(what[1], what2[2])
grepl(what[4], what2[4])
install.packages("stringdist")
library("stringdist")
amatch(what, what2)
amatch(what, what2,maxDist=10)
amatch(what, what2)
what
what1
what2
stringdist(what, what2)
stringdist(what[1], what2)
stringdist(what[2], what2)
stringdist(what[3], what2)
stringdist(what[4], what2)
what2 <- c("his", "is", "an")
stringdist(what[4], what2)
what2 <- c("his", "is", "an")
stringdist(what[4], what2)
stringdist(what[3], what2)
stringdist(what[2], what2)
stringdist(what[4], what2[3])
stringdistmatrix(c("foo","bar","boo","baz"))
stringdistmatrix(what)
stringdistmatrix(what, what2)
what
what2
what2 <- c("his", "is", "an", "great", "text")
what
what2
stringdistmatrix(what, what2)
stringdistmatrix(what, what2, useNames="strings")
what
what2
stringdistmatrix(what, what2, useNames="strings")
setwd("~/OneDrive/ArabicTM")
# libraries needed
library(tm)
library(XML)
library(RCurl)
library(plyr)
library(lda)
library(LDAvis)
# read in some stopwords:
# stop_words1 <- stopwords("SMART")
stopwords_latin <- c("ab", "ac", "ad", "adhic", "aliqui", "aliquis", "an", "ante", "apud", "at", "atque", "aut", "autem", "cum", "cur", "de", "deinde", "dum", "ego", "enim", "ergo", "es", "est", "et", "etiam", "etsi", "ex", "fio", "haud", "hic", "iam", "idem", "igitur", "ille", "in", "infra", "inter", "interim", "ipse", "is", "ita", "magis", "modo", "mox", "nam", "ne", "nec", "necque", "neque", "nisi", "non", "nos", "o", "ob", "per", "possum", "post", "pro", "quae", "quam", "quare", "qui", "quia", "quicumque", "quidem", "quilibet", "quis", "quisnam", "quisquam", "quisque", "quisquis", "quo", "quoniam", "sed", "si", "sic", "sive", "sub", "sui", "sum", "super", "suus", "tam", "tamen", "trans", "tu", "tum", "ubi", "uel", "uero", "ut", "t", "cos2", "coepio", "sum", "edo")
stopwords_greek <- c("μή", "ἑαυτοῦ", "ἄν", "ἀλλ’", "ἀλλά", "ἄλλοσ", "ἀπό", "ἄρα", "αὐτόσ", "δ’", "δέ", "δή", "διά", "δαί", "δαίσ", "ἔτι", "ἐγώ", "ἐκ", "ἐμόσ", "ἐν", "ἐπί", "εἰ", "εἰμί", "εἴμι", "εἰσ", "γάρ", "γε", "γα^", "ἡ", "ἤ", "καί", "κατά", "μέν", "μετά", "μή", "ὁ", "ὅδε", "ὅσ", "ὅστισ", "ὅτι", "οὕτωσ", "οὗτοσ", "οὔτε", "οὖν", "οὐδείσ", "οἱ", "οὐ", "οὐδέ", "οὐκ", "περί", "πρόσ", "σύ", "σύν", "τά", "τε", "τήν", "τῆσ", "τῇ", "τι", "τί", "τισ", "τίσ", "τό", "τοί", "τοιοῦτοσ", "τόν", "τούσ", "τοῦ", "τῶν", "τῷ", "ὑμόσ", "ὑπέρ", "ὑπό", "ὡσ", "ὦ", "ὥστε", "ἐάν", "παρά", "σόσ")
# stop_words3 <- c()
# Decide which set of stopwords
stop_words <- stopwords_latin
XMLpassage <-function(xdata){
dumFun <- function(x){
xname <- xmlName(x)
xattrs <- xmlAttrs(x)
c(sapply(xmlChildren(x), xmlValue), name = xname, xattrs)
}
dum <- xmlParse(xdata)
as.data.frame(t(xpathSApply(dum, "//*/tei:body", dumFun)), stringsAsFactors = FALSE)
}
# output_list[[i]] <- XMLpassage(URLcontent)
# message("---------------------------------------")
}
# t2 <- Sys.time()
# Fetch_time <- t2 - t1
# Build corpus
# corpus <- do.call("rbind",output_list) #combine all vectors into a matrix
# corpus <- unique(corpus) # returns the unique rows of catalogue.
# Save corpus to disk
# write.table(corpus, file = 'corpus.csv', append = FALSE, quote = FALSE, sep = ",", eol = "\n", na = "NA", dec = ".", row.names = TRUE, col.names = TRUE)
# Build base for topic modelling
# research_corpus <- corpus[,"div"]
# research_corpus <- factor(research_corpus)output_names <- read.csv("CartoonSep2013/CartoonSep2013.csv")$identifier
# output_names <- rownames(corpus)
base_corpus <- read.table("Shamela_0035100.csv", sep="\t", header=FALSE)
View(base_corpus)
base_corpus$1
base_corpus[1]
base_corpus[2]
base_corpus["V1"]
base_corpus[["V1"]]
research_corpus <- base_corpus[["V2"]]
output_names <- base_corpus[["V1"]]
research_corpus <- gsub("[[:punct:]]", " ", research_corpus)  # replace punctuation with space
research_corpus <- gsub("[[:cntrl:]]", " ", research_corpus)  # replace control characters with space
research_corpus <- gsub("^[[:space:]]+", "", research_corpus) # remove whitespace at beginning of documents
research_corpus <- gsub("[[:space:]]+$", "", research_corpus) # remove whitespace at end of documents
research_corpus <- gsub("[0-9]", "", research_corpus) #remove numbers
###
# research_corpus <- gsub(" sum ", " ", research_corpus)  # remove esse
# research_corpus <- gsub(" es ", " ", research_corpus)  # remove esse
# research_corpus <- gsub(" est ", " ", research_corpus)  # remove esse
# research_corpus <- gsub(" sumus ", " ", research_corpus)  # remove esse
# research_corpus <- gsub(" estis ", " ", research_corpus)  # remove esse
# research_corpus <- gsub(" sunt ", " ", research_corpus)  # remove esse
# research_corpus <- gsub(" esse ", " ", research_corpus)  # remove esse
research_corpus <- gsub(" cum ", " ", research_corpus)  # remove cum
# produce dictionary for stemming:
t1 <- Sys.time()
corpus_words <- unique(unlist(strsplit(research_corpus, "\\W+", perl=TRUE)))
corpus_words <- sort(corpus_words)
#function for stemming
parsing <- function(x){
URL <- paste("http://www.perseus.tufts.edu/hopper/xmlmorph?lang=lat&lookup=", x, sep = "")
message("Accessing ", URL)
XMLpassage <-function(xdata){
miner <- function(x){
xname <- xmlName(x)
xattrs <- xmlAttrs(x)
c(sapply(xmlChildren(x), xmlValue), name = xname, xattrs)
}
result <- xmlParse(xdata)
temp.df <- as.data.frame(t(xpathSApply(result, "//*/lemma", miner)), stringsAsFactors = FALSE)
as.vector(temp.df[['text']])
}
URLcontent <- tryCatch(
{
getURLContent(URL)
},
error = function(err)
{
message(x, " -query caused server error. Return original value.")
lemma <- x
return(lemma)
})
lemma <- tryCatch(
{
XMLpassage(URLcontent)
},
error = function(err)
{
message(x, " not found. Return original value.")
lemma <- x
return(lemma)
})
lemma <- gsub("[0-9]", "", lemma)
lemma <- tolower(lemma)
lemma <- unique(lemma)
lemma <- paste(lemma, sep="", collapse="_")
if (nchar(lemma) == 0) lemma <- x
message(x, " is ", lemma)
return(lemma)}
correcting <- function(x){
object <- unlist(x)
# corrected <- mapvalues(object, from=names(stem_dictionary), to=tolower(stem_dictionary), warn_missing = FALSE)
corrected <- mapvalues(object, from=tolower(original), to=tolower(new), warn_missing = FALSE)
corrected <- paste(corrected, collapse=" ")
return(corrected)}
#stemming
# stem_dictionary <- sapply(corpus_words, parsing)
# write.table(stem_dictionary, file = 'stem_dictionary1.csv', append = FALSE, quote = FALSE, sep = ",", eol = "\n", na = "NA", dec = ".", row.names = TRUE, col.names = TRUE)
# write.table(as.data.frame(number_lemmata), file = 'stem_overview.csv', append = FALSE, quote = FALSE, sep = ",", eol = "\n", na = "NA", dec = ".", row.names = TRUE, col.names = TRUE)
# NumberOfForms <- max(unique(sapply(stem_dictionary, length)))
# stem_dictionary <- read.table("stem_dictionary_ultimate.csv", sep = " ")
# number_lemmata <- sapply(stem_dictionary, length)
# stem_dictionary <- as.data.frame(stem_dictionary)
# original <- rownames(stem_dictionary)
# new <- as.character(stem_dictionary[,1])
# temp <- strsplit(research_corpus, " ")
# temp_correct <- lapply(temp, correcting)
# research_corpus <- unlist(temp_correct)
# t2 <- Sys.time()
# correcting_time <- t2 - t1
###
head(research_corpus)
# tokenize on space and output as a list:
doc.list <- strsplit(research_corpus, "[[:space:]]+")
# compute the table of terms:
term.table <- table(unlist(doc.list))
term.table <- sort(term.table, decreasing = TRUE)
# remove terms that are stop words or occur fewer than "occurenses" times:
occurences <- 3
del <- names(term.table) %in% stop_words | term.table < occurences
term.table <- term.table[!del]
vocab <- names(term.table)
# now put the documents into the format required by the lda package:
get.terms <- function(x) {
index <- match(x, vocab)
index <- index[!is.na(index)]
rbind(as.integer(index - 1), as.integer(rep(1, length(index))))
}
documents <- lapply(doc.list, get.terms)
